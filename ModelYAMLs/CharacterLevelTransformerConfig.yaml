model_identifier: "CharacterLevelTransformer" 

num_heads: 6
layers: 6
batch_size: 64
context_length: 256
embedding_size: 384
dropout: 0.2
learning_rate: .0003
lr_decay: 0.99
num_epochs: 10

dataset: "shakespeare.txt"

tokenizer_filename: "token_to_id.pkl"
tokenized_dataset: "tokenized_data.pkl"

tokenizer:
  type: "SingleLetterTokenizer"
dataloader:
  type: "SimpleTextDataset"
embedding_0:
  type: "SimplePositionalEmbedding"
embedding_1:
  type: "SimpleSemanticEmbedding"
architecture:
  type: "SimpleDecoder"