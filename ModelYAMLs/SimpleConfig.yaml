model_identifier: "SimpleTransformer" 

num_heads: 6
layers: 6
batch_size: 64
context_length: 32
embedding_size: 384
dropout: 0.2
learning_rate: .0003
lr_decay: 0.99
num_epochs: 64
train_split: 0.8
val_split: 0.1
estimation_amt: 1000

dataset: "shakespeare.txt"

tokenizer_filename: "token_to_id.pkl"
tokenized_dataset: "tokenized_data.pkl"

tokenizer:
  type: "SimpleTokenizer"
dataloader:
  type: "SimpleTextDataset"
embedding_0:
  type: "SimplePositionalEmbedding"
embedding_1:
  type: "SimpleSemanticEmbedding"
architecture:
  type: "SimpleDecoder"